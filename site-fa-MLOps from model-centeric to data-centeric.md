---
authors:
  - name: Mohammad Ali Amini
    email: aliamini@ut.ac.ir
    link:
    avatar: https://lh3.googleusercontent.com/a-/AOh14GiJyjXMkUDZ1L99F7wb2m1Ix3fKejphGF5QMAOxwg=s288-p-rw-no
category:
date: 2022-02-18
description:
icon:
image: ..\static\shutterstock_250696570-Converted-1000x462.jpg
label: null
layout: default
order: 2
tags:
title:
visibility: public

---
# ام-ال-آپس: از مدل-محوری تا داده محوری 

<div dir="rtl">

جدیدا یک وبینار از Andrew Ng درباره MLOps و هوش مصنوعی داده-محور ( در مقابل مدل-محور) نگاه کردم که بسیار جالب بود. در این یادداشت خلاصه نکاتی که در این وبینار مطرح شد رو مینویسم.

<iframe width="700" height="400" src="https://www.youtube.com/embed/06-AZXmwHjo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


سیستم های هوش مصنوعی از داده و کد تشکیل شده اند.


![](../static/Pasted_image_20220211182002_1.png)

اکثریت پیشرفتی که در دو دهه گذشته در زمینه هوش مصنوعی انجام شده است، به این صورت بوده است که دانشمندان و محققان با استفاده از دادگان استاندارد سعی کرده اند که مدل ها و الگوریتم های خود را قوی تر کنند. به عبارت دیگر، تمرکز تحقیق و نوآوری بر روی بهبود الگوریتم ها و مدل ها بوده است و کمتر بر روی داده، کیفیت آن و تاثیرات آن تحقیق و مطالعه انجام شده است. در صورتی که در مثال های متعدد دیده شده است که تاثیر بهبود داده میتواند بسیار چشمگیر تر از بهبود الگوریتم باشد.

## مثالی از اهمیت اصلاح داده ورودی در بهبود نتایج یادگیری ماشین
به عنوان مثال مسئله شناسایی خرابی های ورق های فولادی را در نظر بگیرید. ( این یک مثال واقعی است که در شرکت [Landing AI](https://landing.ai/) مطرح و حل شده است.)

![](../static/Pasted_image_20220211184246_1.png)

در ورق های فولادی 34 مورد خرابی های مختلف میتواند وجود داشته باشد که در شکل بالا نمونه هایی از آن ها را مشاهده می کنید. با استفاده از یک مدل پیشفرض که در مخازن متن باز موجود است و آموزش داده های موجود با آن، دقت اولیه به حدود 76 درصد رسیده است. حال برای این که به دقت 90 درصد برسیم چه باید بکنیم؟ دو راه کلی وجود دارد. یکی این که مدل را بهبود دهیم و دیگری این که داده را بهبود دهیم. در ستون اول جدول زیر  نتیجه ای که از امتحان هر دو روش حاصل شده است مشاهده می کنید.
![](../static/Pasted_image_20220211185751_1.png)

در جدول بالا نتایج برای دو مثال مشابه در دو صنعت دیگر نیز آورده شده است. همانطور که قابل مشاهده است، اصلاح داده همواره موثر تر از بهبود الگوریتم بوده است و گاها اختلاف آن ها نیز زیاد است. نکته دومی که از این نتایج برداشت میشود این است که به نظر میرسد بهبود عملکرد از طریق بهبود مدل کار بسیار سختی است و در هر سه مدل تقریبا بهبود قابل توجهی با اصلاح مدل ها حاصل نشده است .

**این مثال نشان میدهد که اصلاح داده اگر از اصلاح مدل مهم تر نباشد، اهمیت کمتری نیز ندارد. خود مهندسان یادگیری ماشین  نیز اذعان دارند که 80 درصد وقت آن ها صرف آماده سازی داده میشود. ولی آمارها نشان میدهد که میزان تحقیقات در مدل ها و الگوریتم ها به هیچ عنوان با میزان تحقیقات در مورد داده در تعادل قرار ندارد. به صورتی که یک تحقیق دم دستی در arxiv نشان میدهد که 99 درصد مقالات اخیر در حوزه یادگیری ماشین در  حوزه الگوریتم ها و مدل ها هستند و تنها 1 درصد از مقاله ها در مورد داده ها  بحث می کنند.**

## تغییر دیدگاه از مدل-محور به داده محور 
در دیدگاه مدل-محور، روند حل مسئله به این ترتیب است که در حد توان داده جمع میکنیم و بعد از آن مدلی را توسعه می دهیم که به اندازه کافی خوب باشد تا نویز موجود در دادگان را هندل کند. در مقابل، در دیدگاه داده-محور، روند حل مسئله به این ترتیب است که در حد توان داده جمع می کنیم، سپس کیفیت داده را تا حد توان بالا میبریم به صورتی که احتمالا چندین مدل مختلف بر روی آن داده خوب کار خواهند کرد.

![](../static/Pasted_image_20220215221304_1.png)

در عمل دیده شده است که اگر به کیفیت داده اهمیت داده شود، بسیاری از اوقات لازم نیست زیاد به بهینه سازی مدل پرداخت و خیلی از اوقات همان مدل های اولیه نیز به جواب های خوبی منتهی میشوند.
به نظر می رسد که مواجهه با داده کم (در مقیاس 10000 داده و پایین تر) یکی از سناریو های بسیار معمول در استفاده های عملی یادگیری ماشین است. برای مثال در عکس زیر توزیع تعداد داده های دیتاست های kaggle را مشاهده می کنید.

![](../static/Pasted_image_20220216230944_1.png)

اگر تعداد داده ها کم باشد ( که در بسیاری از موارد اینطور است)، اهمیت بالا بردن کیفیت داده بیش تر نیز میشود. همانطور که از شکل زیر نیز قابل مشاهده است، در صورتی که داده ها زیاد باشند، تعدد داده باعث میشود که اثر نویز داده در مدل سازی کاهش یابد، ولی در صورتی که داده کم باشد، نویز در داده باعث میشود که مدل سازی دچار اشکال شود. در این موارد، یک راه با ارزش، بالا بردن کیفیت داده است تا با همان داده کم نیز به مدل درست دست پیدا کنیم.

![](../static/Pasted_image_20220216212718_1.png)
البته راه دیگر نیز این است که تعداد داده ها را بالا تر ببریم. هر چند در بسیاری از زمینه ها، اضافه کردن داده کار ساده ای نیست.
در شکل زیر نمایی از مقایسه این دو روش قابل مشاهده است.

![](../static/Pasted_image_20220216213143_1.png)
نکته دیگری که در اضافه کردن داده وجود دارد این  است که خیلی از اوقات مشکلاتی که در الگوریتم ها وجود دارد، به دلیل کم بودن داده در یک سری سناریوی خاص که لزوما زیاد اتفاق نمی افتند است. در نتیجه اضافه کردن بی دقت داده، به این دلیل که آن سناریوها لزوما اتفاق نمی افتند، کمکی به افزایش دقت الگوریتم نمی کند. ( یک پادکست از آندره کاراپاسی، رئیس بخش تحقیقات ماشین های خودکار تسلا، دیدم که او نیز کاملا بر این موضوع تاکید داشت که ما هفتاد درصد زمان خود را صرف این میکنیم که بفهمیم مدل هایمان در چه سناریوهایی ضعف دارند و برای آن سناریوها داده اضافی پیدا می کنیم. یعنی آن ها هم بحث بالا بردن کیفیت داده را بسیار اهمیت می دهند.)
در ادامه به این میپردازیم که با چه فرایندی میتوانیم کیفیت داده را در یک پروژه یادگیری ماشین بالاتر ببریم.
چرخه عمر یک پروژه یادگیری ماشین معمولا شامل مراحل زیر است.

![](../static/Pasted_image_20220211191722_1.png)

برای این که دیدگاهمان را از مدل-محور به داده-محور تغییر دهیم، باید در هر کدام از این مراحل این تغییر دیدگاه را اعمال کنیم.

### تغییر دیدگاه در جمع آوری داده
در مرحله جمع آوری داده باید به یکدست بودن داده و برچسب های آن اهمیت بیش تری داد. به عنوان مثال، در نگاه اول هر کدام از برچسب های شکل زیر میتوانند بر چسب درست تشحیص یک ایگوانا باشند. 
![](../static/Pasted_image_20220212212729_1.png)

این که کدام نوع از برچسب زنی مناسب تر است، کم تر اهمیت دارد. نکته مهم تر این است که تمام بر چسب ها از یک قانون تبعیت کنند و سلیقه های مختلف باعث کاهش دقت الگوریتم نشود. در دیدگاه داده-محور باید به دنبال راه هایی سیستماتیک بود که داده ها و برچسب آن ها یکدستی بالاتری پیدا کنند.
مثلا میتوان برای مثال بالا پروسه ای را طراحی کرد که دو لیبل زن مستقل یک سری داده را لیبل بزنند. آنگاه سنجید که در کدام موارد برچسب  آن ها با یکدیگر اختلاف دارند. سپس با اصلاح راهنمایی هایی برچسب گذاری، آن ابهامات را برطرف کرد.

### تغییر دیدگاه در آموزش مدل، تحلیل خطا و بهبود رفت و برگشتی
در این قسمت نیز به جای تمرکز بر روی بهبود مدل پس از مشاهده خطاهای سیستم، تمرکز بر روی بهبود داده با افزودن داده هدفمند، data augmentation، بهبود برچسب ها و ... است.
یا با یک بیان سیستماتیک، باید قدم های زیر را طی کرد.
1. مدل را آموزش دهید.
2. خطا را تحلیل کنید تا قسمت هایی از داده که الگوریتم در آن ها ضعیف است مشخص شوند.
3. با روش هایی مانند، جمع آوری داده، تقویت داده (data augmentation) یا ساخت داده و همچنین تصحیح برچسب ها اگر ضعفی در آن هاست، داده را در نقاط ضعف تقویت کنید.

### تغییر دیدگاه در مرحله استفاده نهایی
حقیقت این است که با رسیدن به مرحله استفاده نهایی (Deployment) چیزی تمام نشده است و معمولا تازه در نیمه راه هستیم. در این مرحله باید به طور پیوسته با بازبینی کارایی مدل و استفاده از داده های جدیدی که به دست می آیند، مدل را بهبود داد.

##   برای سیستماتیک کردن نگاه داده-محور ام ال آپس

![](../static/Pasted_image_20220216225741_1.png)

!!!success
**خلاصه وظایف متخصصان MLOps این است که  در تمامی مراحل یک پروژه یادگیری ماشین از دسترسی به داده با کیفیت و یکدست اطمینان حاصل کنند.** 
!!!

همانطور که در بخش قبل توضیح داده شد، گستره فعالیت مهندس MLOps تمام بخش های جمع آوری، آموزش و پیاده سازی را شامل میشود. در تمامی این مراحل، مهندس MLOps باید به فکر این باشد که چطور داده با کیفیت و یکدست تولید کند.

!!!
**باید از "داده بزرگ" به "داده خوب" مهاجرت کنیم!**
!!!

داده خوب داده ای است که:
- به صورت یکدست و دقیق تعریف شده باشد ( دارای ابهام در برچسب زنی و ... نباشد.)
- موارد و سناریوهای مهم را پوشش دهد. ( پوشش دهی خوبی داشته باشد)
- بازخورد مناسب از داده های فاز پیاده سازی داشته باشد تا دریفت داده و موضوع را کاور کند.
- اندازه و مقیاس مناسبی داشته باشد.

## جمع بندی
- مهم ترین وظیفه MLOps تهیه داده با کیفیت در تمام مراحل چرخه عمر یک پروژه یادگیری ماشین است.
- در نگاه داده محور به جای تمرکز بر روی بهبود ساختار مدل، سوال این است که چگونه داده را بهبود دهیم تا کارایی مدل را بالاتر ببریم.
- نکته مهم این است که چگونه فرایند های MLOps را به صورت بهینه و سیستماتیک در آوریم. همانطور که مهندسین نرم افزار توانستند با توسعه ابزارها و روند های مختلف در ورژنینگ، تست و پیاده سازی، فرایند توسعه کد را بسیار بهبود دهند، در فرایند های بهبود داده (MLOps) نیز باید این ابزارها و روند ها ایجاد شوند.

</div>